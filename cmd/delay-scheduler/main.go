// cmd/delay-scheduler-polling/main.go
package main

import (
	"context"
	"jaeger-demo/internal/pkg/mq"
	"jaeger-demo/internal/pkg/tracing"
	"log"
	"os"
	"strings"
	"sync"
	"time"

	"github.com/segmentio/kafka-go"
	"go.opentelemetry.io/otel"
	"go.opentelemetry.io/otel/attribute"
	"go.opentelemetry.io/otel/codes"
	"go.opentelemetry.io/otel/trace"
)

const (
	serviceName = "delay-scheduler-polling"
)

// å®šä¹‰æ”¯æŒçš„å»¶è¿Ÿçº§åˆ«å’Œå¯¹åº”çš„ä¸»é¢˜
var delayLevels = map[string]time.Duration{
	"delay_topic_5s":  5 * time.Second,
	"delay_topic_1m":  1 * time.Minute,
	"delay_topic_10m": 10 * time.Minute,
}

var (
	jaegerEndpoint = getEnv("JAEGER_ENDPOINT", "http://localhost:14268/api/traces")
	kafkaBrokers   = strings.Split(getEnv("KAFKA_BROKERS", "localhost:9092"), ",")
	tracer         = otel.Tracer(serviceName)
)

// Scheduler è´Ÿè´£ç®¡ç†å’Œè¿è¡Œè½®è¯¢ä»»åŠ¡
type Scheduler struct {
	level       string        // å»¶è¿Ÿçº§åˆ«åç§°, e.g., "delay_topic_5s"
	delay       time.Duration // å¯¹åº”çš„å»¶è¿Ÿæ—¶é•¿, e.g., 5s
	kafkaReader *kafka.Reader
	// ä¸ºæ¯ä¸ªçº§åˆ«ç»´æŠ¤ä¸€ä¸ªç‹¬ç«‹çš„ writer, é¿å…å¹¶å‘é—®é¢˜
	kafkaWriters map[string]*kafka.Writer // key: realTopic, value: writer
	writerLock   sync.Mutex
}

// NewScheduler åˆ›å»ºä¸€ä¸ªé’ˆå¯¹ç‰¹å®šå»¶è¿Ÿçº§åˆ«çš„æ–°è°ƒåº¦å™¨
func NewScheduler(level string, delay time.Duration) *Scheduler {
	reader := mq.NewKafkaReader(kafkaBrokers, level, serviceName+"-group-"+level)
	return &Scheduler{
		level:        level,
		delay:        delay,
		kafkaReader:  reader,
		kafkaWriters: make(map[string]*kafka.Writer),
	}
}

// StartPolling å¯åŠ¨å®šæ—¶è½®è¯¢å™¨
func (s *Scheduler) StartPolling(ctx context.Context, interval time.Duration) {
	log.Printf("âœ… Polling scheduler for level '%s' started, checking every %v", s.level, interval)
	// æ¯ä¸ªå»¶è¿Ÿç­‰çº§ä¸€ä¸ªç‹¬ç«‹çš„ ticker
	ticker := time.NewTicker(interval)
	defer ticker.Stop()
	defer s.kafkaReader.Close()
	defer s.closeWriters()

	for {
		select {
		case <-ticker.C:
			s.checkAndPublish(ctx)
		case <-ctx.Done():
			log.Printf("ğŸ›‘ Shutting down polling for level '%s'", s.level)
			return
		}
	}
}

// checkAndPublish æ˜¯è½®è¯¢çš„æ ¸å¿ƒé€»è¾‘
func (s *Scheduler) checkAndPublish(parentCtx context.Context) {
	for {
		// 1. ä½¿ç”¨ FetchMessage è€Œä¸æ˜¯ ReadMessage, è¿™æ ·æˆ‘ä»¬å¯ä»¥æ§åˆ¶æäº¤æµç¨‹
		// FetchMessage ä¸ä¼šè‡ªåŠ¨æäº¤ offset
		msg, err := s.kafkaReader.FetchMessage(parentCtx)
		if err != nil {
			if err == context.Canceled || err.Error() == "context deadline exceeded" {
				// æ­£å¸¸é€€å‡ºæˆ–è¶…æ—¶ï¼Œä¸æ˜¯é”™è¯¯
			} else {
				// å¦‚æœæ²¡æœ‰æ¶ˆæ¯å¯è¯»ï¼Œkafka-go ä¼šè¿”å›ä¸€ä¸ªé”™è¯¯ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œé€€å‡ºå¾ªç¯ï¼Œç­‰å¾…ä¸‹ä¸€æ¬¡ tick
				// log.Printf("DEBUG: No new messages in '%s', waiting for next tick. Err: %v", s.level, err)
			}
			break // é€€å‡º for å¾ªç¯
		}

		propagator := otel.GetTextMapPropagator()
		header := mq.KafkaHeaderCarrier(msg.Headers)
		spanCtx := propagator.Extract(parentCtx, &header)
		now := time.Now().UTC()
		ctx, span := tracer.Start(spanCtx, "scheduler.CheckAndPublish", trace.WithAttributes(
			attribute.String("delay.level", s.level),
			attribute.String("now", now.Format(time.DateTime)),
			attribute.String("msg.Time", msg.Time.Format(time.DateTime)),
			attribute.String("delay", msg.Time.Add(s.delay).Format(time.DateTime)),
		))

		// 2. è®¡ç®—ç†è®ºæŠ•é€’æ—¶é—´ (æ¶ˆæ¯å­˜å‚¨æ—¶é—´ + å»¶è¿Ÿ)
		// Kafka æ¶ˆæ¯çš„ Time å­—æ®µè®°å½•äº†å…¶è¿›å…¥ä¸»é¢˜çš„æ—¶é—´æˆ³
		deliveryTime := msg.Time.Add(s.delay)

		// 3. åˆ¤æ–­æ˜¯å¦åˆ°æœŸ
		if now.After(deliveryTime) {
			// æ¶ˆæ¯åˆ°æœŸï¼Œè¿›è¡ŒæŠ•é€’
			log.Printf("INFO: Message in '%s' is due. DeliveryTime: %v, Now: %v. Publishing...", s.level, deliveryTime, time.Now())

			realTopic := s.getHeader(msg.Headers, "real-topic")
			if realTopic == "" {
				log.Printf("ERROR: 'real-topic' header missing in message from '%s'. Skipping.", s.level)
				// è¿™ç§é”™è¯¯æ¶ˆæ¯ä¹Ÿéœ€è¦æäº¤ï¼Œå¦åˆ™ä¼šä¸€ç›´è¢«é‡å¤æ¶ˆè´¹
				if err := s.kafkaReader.CommitMessages(ctx, msg); err != nil {
					log.Printf("ERROR: Failed to commit message after skipping: %v", err)
				}
				span.End()
				continue // å¤„ç†ä¸‹ä¸€æ¡æ¶ˆæ¯
			}

			// æŠ•é€’åˆ°çœŸå® Topic
			if err := s.publish(ctx, realTopic, msg); err != nil {
				log.Printf("ERROR: Failed to publish message to real topic '%s': %v", realTopic, err)
				// æŠ•é€’å¤±è´¥ï¼Œä¸èƒ½æäº¤ offsetï¼Œç­‰å¾…ä¸‹æ¬¡è½®è¯¢é‡è¯•
				span.RecordError(err)
				span.SetStatus(codes.Error, "Failed to publish to real topic")
				span.End()
				break // é€€å‡ºå¾ªç¯ï¼Œé˜²æ­¢å¤„ç†åç»­æ¶ˆæ¯
			}

			// æŠ•é€’æˆåŠŸï¼Œæäº¤ offset
			if err := s.kafkaReader.CommitMessages(ctx, msg); err != nil {
				log.Printf("ERROR: Failed to commit message for '%s' after successful publish: %v", s.level, err)
				span.RecordError(err)
				span.End()
				// å³ä½¿æäº¤å¤±è´¥ï¼Œä¹Ÿé€€å‡ºå¾ªç¯ï¼Œé¿å…æ¶ˆæ¯é‡å¤æŠ•é€’ã€‚Kafka consumer group ä¼šå¤„ç†å¥½ offset
				break
			}
			log.Printf("SUCCESS: Message from '%s' published to '%s' and committed.", s.level, realTopic)
			span.AddEvent("MessagePublishedAndCommitted", trace.WithAttributes(attribute.String("real.topic", realTopic)))
			span.End()
		} else {
			// é˜Ÿå¤´æ¶ˆæ¯æœªåˆ°æœŸï¼Œæ— éœ€å†æ£€æŸ¥åç»­æ¶ˆæ¯
			// log.Printf("DEBUG: Head message in '%s' not yet due (DeliveryTime: %v). Waiting for next tick.", s.level, deliveryTime)
			span.AddEvent("HeadMessageNotDue")
			span.End()
			break // é€€å‡º for å¾ªç¯
		}
	}
}

// publish å°†æ¶ˆæ¯æŠ•é€’åˆ°çœŸå®ä¸šåŠ¡ä¸»é¢˜
func (s *Scheduler) publish(ctx context.Context, realTopic string, msg kafka.Message) error {
	s.writerLock.Lock()
	writer, exists := s.kafkaWriters[realTopic]
	if !exists {
		writer = mq.NewKafkaWriter(kafkaBrokers, realTopic)
		s.kafkaWriters[realTopic] = writer
	}
	s.writerLock.Unlock()

	// é‡æ–°æ„é€ æ¶ˆæ¯ï¼Œå¹¶æ³¨å…¥è¿½è¸ªä¸Šä¸‹æ–‡
	publishMsg := kafka.Message{
		Key:   msg.Key,
		Value: msg.Value,
	}
	traceCtx := mq.ExtractTraceContext(ctx, msg.Headers)
	mq.InjectTraceContext(traceCtx, &publishMsg.Headers)

	return writer.WriteMessages(ctx, publishMsg)
}

// closeWriters å®‰å…¨åœ°å…³é—­æ‰€æœ‰ writer
func (s *Scheduler) closeWriters() {
	s.writerLock.Lock()
	defer s.writerLock.Unlock()
	for topic, writer := range s.kafkaWriters {
		if err := writer.Close(); err != nil {
			log.Printf("ERROR: Failed to close writer for topic %s: %v", topic, err)
		}
	}
}

func (s *Scheduler) getHeader(headers []kafka.Header, key string) string {
	for _, h := range headers {
		if h.Key == key {
			return string(h.Value)
		}
	}
	return ""
}

func main() {
	tp, err := tracing.InitTracerProvider(serviceName, jaegerEndpoint)
	if err != nil {
		log.Fatalf("failed to initialize tracer provider: %v", err)
	}
	defer tp.Shutdown(context.Background())

	ctx, cancel := context.WithCancel(context.Background())
	defer cancel()

	var wg sync.WaitGroup

	// ä¸ºæ¯ä¸ªå»¶è¿Ÿçº§åˆ«å¯åŠ¨ä¸€ä¸ªç‹¬ç«‹çš„è°ƒåº¦å™¨ goroutine
	for level, delay := range delayLevels {
		wg.Add(1)
		scheduler := NewScheduler(level, delay)
		go func() {
			defer wg.Done()
			// è½®è¯¢å‘¨æœŸä¸º1ç§’ï¼Œä¸æ‚¨æè¿°çš„ä¸€è‡´
			scheduler.StartPolling(ctx, 1*time.Second)
		}()
	}

	log.Println("All polling schedulers are running.")
	wg.Wait()
}

func getEnv(key, fallback string) string {
	if value, ok := os.LookupEnv(key); ok {
		return value
	}
	return fallback
}
