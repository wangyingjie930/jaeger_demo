// internal/service/order/infrastructure/adapter/kafka_consumer_adapter.go
package interfaces

import (
	"context"
	"encoding/json"
	"nexus/internal/pkg/logger"
	"nexus/internal/pkg/mq"
	"nexus/internal/service/order/application"
	"nexus/internal/service/order/domain"
	"sync"
	"time"

	"go.opentelemetry.io/otel"

	"github.com/segmentio/kafka-go"
)

// OrderConsumerAdapter æ˜¯ä¸€ä¸ªé©±åŠ¨é€‚é…å™¨ï¼Œå®ƒç›‘å¬Kafkaæ¶ˆæ¯å¹¶é©±åŠ¨åº”ç”¨æœåŠ¡ã€‚
type OrderConsumerAdapter struct {
	reader  *kafka.Reader
	appSvc  *application.OrderApplicationService // <-- ä¾èµ–åº”ç”¨æœåŠ¡å±‚çš„æ¥å£
	wg      sync.WaitGroup
	stopped bool

	failureHandler *mq.FailureHandler // âœ¨ æ³¨å…¥FailureHandler
	delay          time.Duration      // âœ¨ æ–°å¢å»¶è¿Ÿå­—æ®µ
}

// NewOrderConsumerAdapter åˆ›å»ºä¸€ä¸ªæ–°çš„Kafkaæ¶ˆè´¹è€…é€‚é…å™¨ã€‚
func NewOrderConsumerAdapter(reader *kafka.Reader, appSvc *application.OrderApplicationService, failureHandler *mq.FailureHandler) *OrderConsumerAdapter {
	return &OrderConsumerAdapter{
		reader:         reader,
		appSvc:         appSvc,
		failureHandler: failureHandler,
	}
}

func (a *OrderConsumerAdapter) SetDelay(d time.Duration) {
	a.delay = d
}

// Start å¼€å§‹ç›‘å¬Kafkaä¸»é¢˜ã€‚è¿™æ˜¯ä¸€ä¸ªé•¿æœŸè¿è¡Œçš„æ–¹æ³•ã€‚
func (a *OrderConsumerAdapter) Start(ctx context.Context) error {
	a.wg.Add(1)
	go func() {
		defer a.wg.Done()
		logger.Ctx(ctx).Printf("âœ… Kafka Consumer Adapter started for topic '%s'.", a.reader.Config().Topic)
		for {
			if a.stopped {
				return
			}
			// æˆ‘ä»¬ä½¿ç”¨FetchMessageè€Œä¸æ˜¯ReadMessageï¼Œä»¥ä¾¿æ›´å¥½åœ°æ§åˆ¶é€€å‡ºé€»è¾‘
			msg, err := a.reader.FetchMessage(ctx)
			if err != nil {
				// å¦‚æœæ˜¯ä¸Šä¸‹æ–‡å–æ¶ˆå¯¼è‡´çš„é”™è¯¯ï¼Œåˆ™æ­£å¸¸é€€å‡º
				if ctx.Err() != nil {
					logger.Ctx(ctx).Error().Err(ctx.Err()).Msg("ğŸ›‘ Kafka Consumer Adapter shutting down.")
					return
				}
				logger.Ctx(ctx).Printf("ERROR: could not read message: %v. Retrying...", err)
				time.Sleep(1 * time.Second) // é¿å…å¿«é€Ÿå¤±è´¥å¾ªç¯
				continue
			}

			// âœ¨ å»¶è¿Ÿå¤„ç†é€»è¾‘
			if a.delay > 0 {
				deliveryTime := msg.Time.Add(a.delay)
				logger.Ctx(ctx).Info().Any("checkTime", time.Now().Before(deliveryTime)).
					Any("deliveryTime", deliveryTime.Format(time.DateTime)).
					Any("now", time.Now().Format(time.DateTime)).
					Msgf("æ£€æŸ¥æ¶ˆæ¯!")

				time.Sleep(deliveryTime.Sub(time.Now()))
			}

			propagator := otel.GetTextMapPropagator()
			headerCarrier := mq.KafkaHeaderCarrier(msg.Headers)
			newCtx := propagator.Extract(ctx, &headerCarrier)

			// âœ¨ å°†å¤„ç†é€»è¾‘ç§»å…¥ä¸€ä¸ªå¸¦é”™è¯¯è¿”å›çš„å‡½æ•°
			processingErr := a.processMessage(newCtx, msg)

			if processingErr != nil {
				// âœ¨ å¦‚æœå¤„ç†å¤±è´¥ï¼Œè°ƒç”¨FailureHandler
				a.failureHandler.Handle(newCtx, msg, processingErr)
			}

			// âœ¨ æ— è®ºæˆåŠŸæˆ–å¤±è´¥ï¼ˆå·²ç§»äº¤ï¼‰ï¼Œéƒ½æäº¤Offset
			if err := a.reader.CommitMessages(ctx, msg); err != nil {
				logger.Ctx(ctx).Error().Err(err).Msg("Failed to commit messages")
			}
		}
	}()
	return nil
}

// Stop ä¼˜é›…åœ°åœæ­¢æ¶ˆè´¹è€…ã€‚
func (a *OrderConsumerAdapter) Stop(ctx context.Context) {
	a.stopped = true
	a.reader.Close()
	a.wg.Wait()
	logger.Ctx(ctx).Printf("âœ… Kafka Consumer Adapter stopped.")
}

// processMessage ååºåˆ—åŒ–æ¶ˆæ¯å¹¶è°ƒç”¨åº”ç”¨æœåŠ¡ã€‚
func (a *OrderConsumerAdapter) processMessage(ctx context.Context, msg kafka.Message) error {
	//return errors.New("connection timeout")
	// è§£ææ¶ˆæ¯ä½“
	var event domain.OrderCreationRequested
	if err := json.Unmarshal(msg.Value, &event); err != nil {
		return err
	}

	// è°ƒç”¨åº”ç”¨æœåŠ¡æ¥å¤„ç†ä¸šåŠ¡é€»è¾‘
	return a.appSvc.HandleOrderCreationEvent(ctx, &event)
}
